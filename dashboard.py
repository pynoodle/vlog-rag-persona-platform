# -*- coding: utf-8 -*-
import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
import json
import os
import glob
from collections import Counter, defaultdict
from datetime import datetime

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="YouTube ì˜ìƒ ë°ì´í„° ë¶„ì„ ëŒ€ì‹œë³´ë“œ",
    page_icon="ğŸ“±",
    layout="wide",
    initial_sidebar_state="expanded"
)

# CSS ìŠ¤íƒ€ì¼ë§ - ë‹¤í¬ëª¨ë“œ ëŒ€ì‘
st.markdown("""
<style>
    .main-header {
        font-size: 3rem;
        font-weight: bold;
        color: #FF0000;
        text-align: center;
        margin-bottom: 2rem;
    }
    
    /* ëª¨ë“  í…ìŠ¤íŠ¸ ìš”ì†Œì— ëŒ€í•´ ëª…ì‹œì  ìƒ‰ìƒ ì§€ì • */
    [data-testid="stMarkdownContainer"] p,
    [data-testid="stMarkdownContainer"] span,
    [data-testid="stMarkdownContainer"] div,
    .stMarkdown p,
    .stMarkdown span,
    .stMarkdown div {
        color: #1f1f1f !important;
    }
    
    /* ë‹¤í¬ í…Œë§ˆì¸ ê²½ìš° í°ìƒ‰ìœ¼ë¡œ */
    @media (prefers-color-scheme: dark) {
        [data-testid="stMarkdownContainer"] p,
        [data-testid="stMarkdownContainer"] span,
        [data-testid="stMarkdownContainer"] div,
        .stMarkdown p,
        .stMarkdown span,
        .stMarkdown div {
            color: #ffffff !important;
        }
    }
    
    /* ë©”íŠ¸ë¦­ ì¹´ë“œ */
    .stMetric {
        background-color: #ffffff;
        padding: 1rem;
        border-radius: 0.5rem;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
    }
    
    [data-testid="stMetricLabel"],
    [data-testid="stMetricValue"] {
        color: #1f1f1f !important;
    }
    
    /* í—¤ë” ìƒ‰ìƒ */
    h1, h2, h3, h4, h5, h6 {
        color: #1f1f1f !important;
    }
    
    @media (prefers-color-scheme: dark) {
        h1, h2, h3, h4, h5, h6 {
            color: #ffffff !important;
        }
    }
</style>
""", unsafe_allow_html=True)

@st.cache_data
def load_all_videos(data_dir='youtube_data'):
    """ëª¨ë“  ì˜ìƒ ë°ì´í„°ë¥¼ ë¡œë“œ"""
    videos = []
    
    if not os.path.exists(data_dir):
        return videos
    
    channel_dirs = [d for d in os.listdir(data_dir) 
                   if os.path.isdir(os.path.join(data_dir, d))]
    
    for channel_id in channel_dirs:
        channel_path = os.path.join(data_dir, channel_id)
        
        # ì±„ë„ ì •ë³´
        channel_info_path = os.path.join(channel_path, 'channel_info.json')
        channel_name = channel_id
        
        if os.path.exists(channel_info_path):
            try:
                with open(channel_info_path, 'r', encoding='utf-8') as f:
                    info = json.load(f)
                    channel_name = info.get('channel_title', channel_id)
            except:
                pass
        
        # ì˜ìƒ ë°ì´í„°
        json_files = glob.glob(os.path.join(channel_path, '*.json'))
        
        for json_file in json_files:
            if 'channel_info.json' in json_file:
                continue
            
            try:
                with open(json_file, 'r', encoding='utf-8') as f:
                    video_data = json.load(f)
                
                video_data['channel_name'] = channel_name
                video_data['channel_id'] = channel_id
                
                # ì „ì²´ í…ìŠ¤íŠ¸
                full_text = ""
                if video_data.get('transcript'):
                    full_text = " ".join([seg.get('text', '') for seg in video_data['transcript']])
                
                video_data['full_text'] = full_text
                video_data['has_transcript'] = len(full_text) > 0
                
                videos.append(video_data)
                
            except:
                continue
    
    return videos

def search_videos(videos, keyword):
    """í‚¤ì›Œë“œë¡œ ì˜ìƒ ê²€ìƒ‰"""
    keyword_lower = keyword.lower()
    results = []
    
    for video in videos:
        if not video.get('has_transcript'):
            continue
        
        if keyword_lower in video['full_text'].lower():
            # ë§¤ì¹­ ì„¸ê·¸ë¨¼íŠ¸ ì°¾ê¸°
            matching_segments = []
            for seg in video.get('transcript', []):
                if keyword_lower in seg.get('text', '').lower():
                    matching_segments.append(seg)
            
            results.append({
                **video,
                'match_count': len(matching_segments),
                'matching_segments': matching_segments
            })
    
    return sorted(results, key=lambda x: x['match_count'], reverse=True)

def main():
    # í—¤ë”
    st.markdown('<h1 class="main-header">ğŸ“± YouTube ì˜ìƒ ë°ì´í„° ë¶„ì„ ëŒ€ì‹œë³´ë“œ</h1>', 
                unsafe_allow_html=True)
    
    # ë°ì´í„° ë¡œë“œ
    with st.spinner('ë°ì´í„° ë¡œë”© ì¤‘...'):
        videos = load_all_videos()
    
    if not videos:
        st.error("âŒ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. youtube_data í´ë”ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
        return
    
    # ê¸°ë³¸ í†µê³„
    videos_with_transcript = [v for v in videos if v.get('has_transcript')]
    total_channels = len(set(v['channel_id'] for v in videos))
    
    # ì‚¬ì´ë“œë°” - í•„í„°
    st.sidebar.header("ğŸ” í•„í„°")
    
    # ì±„ë„ ì„ íƒ
    all_channels = sorted(list(set(v['channel_name'] for v in videos)))
    selected_channels = st.sidebar.multiselect(
        "ì±„ë„ ì„ íƒ",
        options=all_channels,
        default=[]
    )
    
    # ìë§‰ ìœ ë¬´ í•„í„°
    transcript_filter = st.sidebar.radio(
        "ìë§‰/STT í•„í„°",
        options=["ì „ì²´", "ìë§‰/STT ìˆìŒ", "ë©”íƒ€ë°ì´í„°ë§Œ"],
        index=0
    )
    
    # í•„í„° ì ìš©
    filtered_videos = videos.copy()
    
    if selected_channels:
        filtered_videos = [v for v in filtered_videos if v['channel_name'] in selected_channels]
    
    if transcript_filter == "ìë§‰/STT ìˆìŒ":
        filtered_videos = [v for v in filtered_videos if v.get('has_transcript')]
    elif transcript_filter == "ë©”íƒ€ë°ì´í„°ë§Œ":
        filtered_videos = [v for v in filtered_videos if not v.get('has_transcript')]
    
    # íƒ­ êµ¬ì„±
    tab1, tab2, tab3, tab4, tab5 = st.tabs([
        "ğŸ“Š ì „ì²´ í†µê³„", 
        "ğŸ” í‚¤ì›Œë“œ ê²€ìƒ‰", 
        "ğŸ“± ìŠ¤ë§ˆíŠ¸í° ë¶„ì„",
        "ğŸ“º ì±„ë„ ë¶„ì„",
        "ğŸ”¥ ì¸ê¸° ì˜ìƒ"
    ])
    
    # ===== íƒ­ 1: ì „ì²´ í†µê³„ =====
    with tab1:
        st.header("ğŸ“Š ì „ì²´ í†µê³„")
        
        # ì£¼ìš” ë©”íŠ¸ë¦­
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric("ì´ ì˜ìƒ ìˆ˜", f"{len(filtered_videos):,}ê°œ")
        
        with col2:
            st.metric("ì±„ë„ ìˆ˜", f"{len(set(v['channel_id'] for v in filtered_videos))}ê°œ")
        
        with col3:
            transcript_count = len([v for v in filtered_videos if v.get('has_transcript')])
            st.metric("ìë§‰/STT ìˆìŒ", f"{transcript_count:,}ê°œ")
        
        with col4:
            transcript_rate = (transcript_count / len(filtered_videos) * 100) if filtered_videos else 0
            st.metric("ìë§‰ ìˆ˜ì§‘ë¥ ", f"{transcript_rate:.1f}%")
        
        st.markdown("---")
        
        # ì±„ë„ë³„ ì˜ìƒ ìˆ˜ ì°¨íŠ¸
        col1, col2 = st.columns(2)
        
        with col1:
            st.subheader("ğŸ“º ì±„ë„ë³„ ì˜ìƒ ìˆ˜")
            
            channel_counts = Counter(v['channel_name'] for v in filtered_videos)
            df_channels = pd.DataFrame(
                channel_counts.most_common(15),
                columns=['ì±„ë„', 'ì˜ìƒ ìˆ˜']
            )
            
            fig = px.bar(df_channels, x='ì˜ìƒ ìˆ˜', y='ì±„ë„', orientation='h',
                        color='ì˜ìƒ ìˆ˜', color_continuous_scale='Reds')
            fig.update_layout(height=500, showlegend=False)
            st.plotly_chart(fig, use_container_width=True)
        
        with col2:
            st.subheader("ğŸ“ ìë§‰/STT íƒ€ì… ë¶„í¬")
            
            transcript_types = Counter(v.get('transcript_type', 'none') 
                                      for v in filtered_videos)
            
            df_types = pd.DataFrame(
                transcript_types.items(),
                columns=['íƒ€ì…', 'ê°œìˆ˜']
            )
            
            type_labels = {
                'subtitle': 'ğŸ“„ ìˆ˜ë™ ìë§‰',
                'auto-generated': 'ğŸ¤– ìë™ ìƒì„±',
                'whisper-stt': 'ğŸ™ï¸ Whisper STT',
                'none': 'âŒ ì—†ìŒ',
                None: 'âŒ ì—†ìŒ'
            }
            df_types['íƒ€ì…'] = df_types['íƒ€ì…'].map(lambda x: type_labels.get(x, x))
            
            fig = px.pie(df_types, values='ê°œìˆ˜', names='íƒ€ì…',
                        color_discrete_sequence=px.colors.qualitative.Set3)
            fig.update_layout(height=500)
            st.plotly_chart(fig, use_container_width=True)
        
        st.markdown("---")
        
        # ì¡°íšŒìˆ˜ ë¶„í¬
        st.subheader("ğŸ‘ï¸ ì¡°íšŒìˆ˜ ë¶„í¬")
        
        view_counts = []
        for v in filtered_videos:
            try:
                view_counts.append(int(v['metadata'].get('view_count', 0)))
            except:
                pass
        
        if view_counts:
            df_views = pd.DataFrame({'ì¡°íšŒìˆ˜': view_counts})
            
            fig = px.histogram(df_views, x='ì¡°íšŒìˆ˜', nbins=50,
                             labels={'ì¡°íšŒìˆ˜': 'ì¡°íšŒìˆ˜', 'count': 'ì˜ìƒ ìˆ˜'})
            fig.update_layout(height=400)
            st.plotly_chart(fig, use_container_width=True)
            
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("í‰ê·  ì¡°íšŒìˆ˜", f"{sum(view_counts)/len(view_counts):,.0f}")
            with col2:
                st.metric("ìµœëŒ€ ì¡°íšŒìˆ˜", f"{max(view_counts):,}")
            with col3:
                st.metric("ì¤‘ì•™ê°’", f"{sorted(view_counts)[len(view_counts)//2]:,}")
    
    # ===== íƒ­ 2: í‚¤ì›Œë“œ ê²€ìƒ‰ =====
    with tab2:
        st.header("ğŸ” í‚¤ì›Œë“œ ê²€ìƒ‰")
        
        col1, col2 = st.columns([3, 1])
        
        with col1:
            search_keyword = st.text_input(
                "ê²€ìƒ‰ í‚¤ì›Œë“œ ì…ë ¥",
                placeholder="ì˜ˆ: ì•„ì´í°, battery, ì¼€ì´ìŠ¤"
            )
        
        with col2:
            st.write("")
            st.write("")
            search_button = st.button("ğŸ” ê²€ìƒ‰", type="primary")
        
        if search_keyword or search_button:
            if search_keyword:
                with st.spinner(f"'{search_keyword}' ê²€ìƒ‰ ì¤‘..."):
                    results = search_videos(videos_with_transcript, search_keyword)
                
                if results:
                    st.success(f"âœ… {len(results)}ê°œ ì˜ìƒì—ì„œ ì´ {sum(r['match_count'] for r in results)}íšŒ ë°œê²¬!")
                    
                    # ê²€ìƒ‰ ê²°ê³¼ í‘œì‹œ
                    for idx, result in enumerate(results[:20], 1):
                        with st.expander(f"{idx}. {result['metadata']['title']} ({result['match_count']}íšŒ ì–¸ê¸‰)"):
                            col1, col2 = st.columns([2, 1])
                            
                            with col1:
                                st.write(f"**ì±„ë„:** {result['channel_name']}")
                                st.write(f"**URL:** {result['metadata']['video_url']}")
                                
                                try:
                                    view_count = int(result['metadata']['view_count'])
                                    st.write(f"**ì¡°íšŒìˆ˜:** {view_count:,}")
                                except:
                                    st.write(f"**ì¡°íšŒìˆ˜:** {result['metadata']['view_count']}")
                            
                            with col2:
                                st.metric("ì–¸ê¸‰ íšŸìˆ˜", f"{result['match_count']}íšŒ")
                            
                            # ë§¤ì¹­ ì„¸ê·¸ë¨¼íŠ¸ í‘œì‹œ
                            st.markdown("**ì–¸ê¸‰ ë‚´ìš©:**")
                            for seg in result['matching_segments'][:3]:
                                timestamp = seg.get('start', 0)
                                minutes = int(timestamp // 60)
                                seconds = int(timestamp % 60)
                                text = seg.get('text', '')
                                
                                st.markdown(f"â±ï¸ `[{minutes:02d}:{seconds:02d}]` {text}")
                            
                            if len(result['matching_segments']) > 3:
                                st.info(f"... ì™¸ {len(result['matching_segments']) - 3}ê°œ ì–¸ê¸‰")
                    
                    if len(results) > 20:
                        st.info(f"... ì™¸ {len(results) - 20}ê°œ ì˜ìƒ (ìƒìœ„ 20ê°œë§Œ í‘œì‹œ)")
                else:
                    st.warning(f"'{search_keyword}'ê°€ í¬í•¨ëœ ì˜ìƒì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    
    # ===== íƒ­ 3: ìŠ¤ë§ˆíŠ¸í° ë¶„ì„ =====
    with tab3:
        st.header("ğŸ“± ìŠ¤ë§ˆíŠ¸í° ê´€ë ¨ ì½˜í…ì¸  ë¶„ì„")
        
        # ìŠ¤ë§ˆíŠ¸í° ê´€ë ¨ í‚¤ì›Œë“œ
        smartphone_keywords = ['smartphone', 'iphone', 'galaxy', 'android', 'phone',
                              'imessage', 'facetime', 'ìŠ¤ë§ˆíŠ¸í°', 'ì•„ì´í°', 'ê°¤ëŸ­ì‹œ', 'í•¸ë“œí°']
        
        # ìŠ¤ë§ˆíŠ¸í° ê´€ë ¨ ì˜ìƒ í•„í„°ë§
        smartphone_videos = []
        for video in videos_with_transcript:
            if any(kw.lower() in video['full_text'].lower() for kw in smartphone_keywords):
                smartphone_videos.append(video)
        
        st.metric("ìŠ¤ë§ˆíŠ¸í° ê´€ë ¨ ì˜ìƒ", f"{len(smartphone_videos)}ê°œ / {len(videos_with_transcript)}ê°œ")
        
        if smartphone_videos:
            # í† í”½ ë¶„ì„
            st.subheader("ğŸ“Š ì£¼ìš” í† í”½ ë¶„í¬")
            
            topics = {
                'ğŸ¨ í° ì¼€ì´ìŠ¤/ì•¡ì„¸ì„œë¦¬': ['case', 'accessories', 'airpods', 'screen protector', 'ì¼€ì´ìŠ¤'],
                'ğŸ”‹ ë°°í„°ë¦¬/ì¶©ì „': ['battery', 'charging', 'charger', 'ë°°í„°ë¦¬', 'ì¶©ì „'],
                'ğŸ“¸ ì´¬ì˜/ì¹´ë©”ë¼': ['camera', 'selfie', 'photo', 'filming', 'ì¹´ë©”ë¼', 'ì…€ì¹´'],
                'ğŸ“² ì•±/ì†Œí”„íŠ¸ì›¨ì–´': ['app', 'ios', 'android', 'widget', 'ì•±'],
                'ğŸ“± ë””ì§€í„¸ ì›°ë¹™': ['screen time', 'addiction', 'notification', 'ìŠ¤í¬ë¦°íƒ€ì„'],
                'ğŸ“¦ ì‹ ì œí’ˆ/ì–¸ë°•ì‹±': ['unboxing', 'iphone 16', 'iphone 15', 'new phone', 'ì–¸ë°•ì‹±'],
                'ğŸ’¬ ë©”ì‹œì§•': ['imessage', 'facetime', 'whatsapp', 'text', 'ë©”ì‹œì§€'],
            }
            
            topic_counts = {}
            for topic_name, keywords in topics.items():
                count = 0
                for video in smartphone_videos:
                    if any(kw.lower() in video['full_text'].lower() for kw in keywords):
                        count += 1
                topic_counts[topic_name] = count
            
            # ì°¨íŠ¸
            df_topics = pd.DataFrame(
                sorted(topic_counts.items(), key=lambda x: x[1], reverse=True),
                columns=['í† í”½', 'ì˜ìƒ ìˆ˜']
            )
            
            fig = px.bar(df_topics, x='ì˜ìƒ ìˆ˜', y='í† í”½', orientation='h',
                        color='ì˜ìƒ ìˆ˜', color_continuous_scale='Viridis')
            fig.update_layout(height=400)
            st.plotly_chart(fig, use_container_width=True)
            
            st.markdown("---")
            
            # ì±„ë„ë³„ ìŠ¤ë§ˆíŠ¸í° ê´€ë ¨ ì˜ìƒ ìˆ˜
            st.subheader("ğŸ“º ì±„ë„ë³„ ìŠ¤ë§ˆíŠ¸í° ì½˜í…ì¸ ")
            
            channel_smartphone = Counter(v['channel_name'] for v in smartphone_videos)
            df_channel_phone = pd.DataFrame(
                channel_smartphone.most_common(10),
                columns=['ì±„ë„', 'ìŠ¤ë§ˆíŠ¸í° ê´€ë ¨ ì˜ìƒ']
            )
            
            fig = px.bar(df_channel_phone, x='ìŠ¤ë§ˆíŠ¸í° ê´€ë ¨ ì˜ìƒ', y='ì±„ë„',
                        orientation='h', color='ìŠ¤ë§ˆíŠ¸í° ê´€ë ¨ ì˜ìƒ',
                        color_continuous_scale='Oranges')
            fig.update_layout(height=400)
            st.plotly_chart(fig, use_container_width=True)
    
    # ===== íƒ­ 4: ì±„ë„ ë¶„ì„ =====
    with tab4:
        st.header("ğŸ“º ì±„ë„ë³„ ë¶„ì„")
        
        # ì±„ë„ ì„ íƒ
        channel_to_analyze = st.selectbox(
            "ë¶„ì„í•  ì±„ë„ ì„ íƒ",
            options=sorted(list(set(v['channel_name'] for v in filtered_videos)))
        )
        
        if channel_to_analyze:
            channel_videos = [v for v in filtered_videos if v['channel_name'] == channel_to_analyze]
            channel_with_text = [v for v in channel_videos if v.get('has_transcript')]
            
            # ì±„ë„ í†µê³„
            col1, col2, col3, col4 = st.columns(4)
            
            with col1:
                st.metric("ì´ ì˜ìƒ", f"{len(channel_videos)}ê°œ")
            
            with col2:
                st.metric("ìë§‰/STT", f"{len(channel_with_text)}ê°œ")
            
            with col3:
                total_views = sum(int(v['metadata'].get('view_count', 0)) 
                                for v in channel_videos 
                                if v['metadata'].get('view_count'))
                st.metric("ì´ ì¡°íšŒìˆ˜", f"{total_views:,}")
            
            with col4:
                avg_views = total_views / len(channel_videos) if channel_videos else 0
                st.metric("í‰ê·  ì¡°íšŒìˆ˜", f"{avg_views:,.0f}")
            
            st.markdown("---")
            
            # ì˜ìƒ ëª©ë¡
            st.subheader("ğŸ¬ ì˜ìƒ ëª©ë¡")
            
            # ì •ë ¬ ì˜µì…˜
            sort_by = st.radio(
                "ì •ë ¬",
                options=["ì¡°íšŒìˆ˜ ë†’ì€ ìˆœ", "ì¡°íšŒìˆ˜ ë‚®ì€ ìˆœ", "ìµœì‹ ìˆœ"],
                horizontal=True
            )
            
            sorted_videos = channel_videos.copy()
            
            if sort_by == "ì¡°íšŒìˆ˜ ë†’ì€ ìˆœ":
                sorted_videos.sort(key=lambda x: int(x['metadata'].get('view_count', 0)), reverse=True)
            elif sort_by == "ì¡°íšŒìˆ˜ ë‚®ì€ ìˆœ":
                sorted_videos.sort(key=lambda x: int(x['metadata'].get('view_count', 0)))
            
            for idx, video in enumerate(sorted_videos[:20], 1):
                metadata = video['metadata']
                video_id = metadata.get('video_id', f'video_{idx}')
                
                with st.expander(f"{idx}. {metadata['title']}"):
                    col1, col2 = st.columns([3, 1])
                    
                    with col1:
                        st.write(f"**URL:** {metadata['video_url']}")
                        st.write(f"**ê²Œì‹œì¼:** {metadata.get('published_at', 'N/A')}")
                        
                        try:
                            view_count = int(metadata['view_count'])
                            st.write(f"**ì¡°íšŒìˆ˜:** {view_count:,}")
                        except:
                            st.write(f"**ì¡°íšŒìˆ˜:** {metadata['view_count']}")
                        
                        st.write(f"**ì¢‹ì•„ìš”:** {metadata.get('like_count', 0)}")
                        st.write(f"**ëŒ“ê¸€:** {metadata.get('comment_count', 0)}")
                    
                    with col2:
                        has_text = "âœ… ìˆìŒ" if video.get('has_transcript') else "âŒ ì—†ìŒ"
                        st.metric("ìë§‰/STT", has_text)
                        
                        trans_type = video.get('transcript_type', 'none')
                        type_emoji = {
                            'subtitle': 'ğŸ“„',
                            'auto-generated': 'ğŸ¤–',
                            'whisper-stt': 'ğŸ™ï¸',
                            'none': 'âŒ'
                        }
                        st.write(f"{type_emoji.get(trans_type, 'â“')} {trans_type}")
                    
                    # ì„¤ëª… (ê³ ìœ  key ì‚¬ìš©)
                    if metadata.get('description'):
                        st.markdown("**ğŸ“ ì„¤ëª…:**")
                        st.text(metadata['description'][:500])
    
    # ===== íƒ­ 5: ì¸ê¸° ì˜ìƒ =====
    with tab5:
        st.header("ğŸ”¥ ì¸ê¸° ì˜ìƒ Top 20")
        
        # í•„í„° ì˜µì…˜
        popularity_filter = st.radio(
            "í•„í„°",
            options=["ì „ì²´", "ìŠ¤ë§ˆíŠ¸í° ê´€ë ¨ë§Œ"],
            horizontal=True
        )
        
        videos_to_rank = filtered_videos.copy()
        
        if popularity_filter == "ìŠ¤ë§ˆíŠ¸í° ê´€ë ¨ë§Œ":
            smartphone_keywords = ['smartphone', 'iphone', 'galaxy', 'android', 'phone',
                                  'ìŠ¤ë§ˆíŠ¸í°', 'ì•„ì´í°', 'ê°¤ëŸ­ì‹œ', 'í•¸ë“œí°']
            videos_to_rank = [v for v in videos_to_rank 
                            if v.get('has_transcript') and 
                            any(kw.lower() in v['full_text'].lower() for kw in smartphone_keywords)]
        
        # ì¡°íšŒìˆ˜ë¡œ ì •ë ¬
        videos_to_rank.sort(key=lambda x: int(x['metadata'].get('view_count', 0)), reverse=True)
        
        for idx, video in enumerate(videos_to_rank[:20], 1):
            metadata = video['metadata']
            
            with st.container():
                col1, col2, col3 = st.columns([1, 5, 2])
                
                with col1:
                    st.markdown(f"### {idx}")
                
                with col2:
                    st.markdown(f"**{metadata['title']}**")
                    st.caption(f"ğŸ“º {video['channel_name']}")
                
                with col3:
                    try:
                        view_count = int(metadata['view_count'])
                        st.metric("ì¡°íšŒìˆ˜", f"{view_count:,}")
                    except:
                        st.metric("ì¡°íšŒìˆ˜", metadata['view_count'])
                
                st.markdown(f"ğŸ”— [{metadata['video_url']}]({metadata['video_url']})")
                st.markdown("---")
    
    # ì‚¬ì´ë“œë°” - í†µê³„ ìš”ì•½
    st.sidebar.markdown("---")
    st.sidebar.header("ğŸ“Š í˜„ì¬ í•„í„° í†µê³„")
    st.sidebar.metric("ì˜ìƒ ìˆ˜", f"{len(filtered_videos)}ê°œ")
    st.sidebar.metric("ìë§‰/STT", f"{len([v for v in filtered_videos if v.get('has_transcript')])}ê°œ")
    
    # í‘¸í„°
    st.sidebar.markdown("---")
    st.sidebar.caption("ğŸ“… ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸: " + datetime.now().strftime('%Y-%m-%d %H:%M'))
    st.sidebar.caption("ğŸ’» YouTube ì˜ìƒ ë°ì´í„° ë¶„ì„ ì‹œìŠ¤í…œ")

if __name__ == "__main__":
    main()

