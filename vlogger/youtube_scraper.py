# -*- coding: utf-8 -*-
import os
import sys
import json
from googleapiclient.discovery import build
from youtube_transcript_api import YouTubeTranscriptApi
from youtube_transcript_api._errors import TranscriptsDisabled, NoTranscriptFound
import yt_dlp
import whisper
import torch
from datetime import datetime
import glob
import time

# Windows ì½˜ì†” ì¸ì½”ë”© ì„¤ì •
if sys.platform == 'win32':
    sys.stdout.reconfigure(encoding='utf-8')

class YouTubeChannelScraper:
    def __init__(self, api_key, channel_id):
        """
        YouTube ì±„ë„ ìŠ¤í¬ë˜í¼ ì´ˆê¸°í™”
        
        Args:
            api_key: YouTube Data API v3 í‚¤
            channel_id: YouTube ì±„ë„ ID (ì˜ˆ: UCxxxxxx)
        """
        self.api_key = api_key
        self.channel_id = channel_id
        self.youtube = build('youtube', 'v3', developerKey=api_key)
        self.whisper_model = None
        
        # GPU ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        print(f"STTì— ì‚¬ìš©í•  ë””ë°”ì´ìŠ¤: {self.device}")
        if self.device == "cuda":
            print(f"GPU: {torch.cuda.get_device_name(0)}")
        
    def get_latest_videos(self, max_results=10):
        """ì±„ë„ì˜ ìµœì‹  ì˜ìƒ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°"""
        print(f"ì±„ë„ì˜ ìµœì‹  {max_results}ê°œ ì˜ìƒì„ ê°€ì ¸ì˜¤ëŠ” ì¤‘...")
        
        # ì±„ë„ì˜ ì—…ë¡œë“œ í”Œë ˆì´ë¦¬ìŠ¤íŠ¸ ID ê°€ì ¸ì˜¤ê¸°
        channel_response = self.youtube.channels().list(
            part='contentDetails',
            id=self.channel_id
        ).execute()
        
        playlist_id = channel_response['items'][0]['contentDetails']['relatedPlaylists']['uploads']
        
        # í”Œë ˆì´ë¦¬ìŠ¤íŠ¸ì—ì„œ ì˜ìƒ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
        videos = []
        request = self.youtube.playlistItems().list(
            part='snippet',
            playlistId=playlist_id,
            maxResults=max_results
        )
        
        response = request.execute()
        
        for item in response['items']:
            video_id = item['snippet']['resourceId']['videoId']
            videos.append(video_id)
            
        return videos
    
    def get_video_metadata(self, video_id):
        """ì˜ìƒì˜ ë©”íƒ€ë°ì´í„° ê°€ì ¸ì˜¤ê¸°"""
        print(f"ì˜ìƒ {video_id}ì˜ ë©”íƒ€ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ëŠ” ì¤‘...")
        
        response = self.youtube.videos().list(
            part='snippet,statistics,contentDetails',
            id=video_id
        ).execute()
        
        if not response['items']:
            return None
            
        video = response['items'][0]
        
        metadata = {
            'video_id': video_id,
            'video_url': f'https://www.youtube.com/watch?v={video_id}',
            'title': video['snippet']['title'],
            'description': video['snippet']['description'],
            'published_at': video['snippet']['publishedAt'],
            'channel_title': video['snippet']['channelTitle'],
            'tags': video['snippet'].get('tags', []),
            'duration': video['contentDetails']['duration'],
            'view_count': video['statistics'].get('viewCount', 0),
            'like_count': video['statistics'].get('likeCount', 0),
            'comment_count': video['statistics'].get('commentCount', 0),
            'thumbnail_url': video['snippet']['thumbnails']['high']['url']
        }
        
        return metadata
    
    def get_transcript(self, video_id):
        """ìë§‰ ê°€ì ¸ì˜¤ê¸° (í•œêµ­ì–´ ìš°ì„ )"""
        print(f"ì˜ìƒ {video_id}ì˜ ìë§‰ì„ ê°€ì ¸ì˜¤ëŠ” ì¤‘...")
        
        try:
            # í•œêµ­ì–´ ìë§‰ ì‹œë„
            transcript_list = YouTubeTranscriptApi.list_transcripts(video_id)
            
            try:
                transcript = transcript_list.find_transcript(['ko'])
                fetched = transcript.fetch()
                time.sleep(0.5)  # ìš”ì²­ ì‚¬ì´ ë”œë ˆì´
                return [{'text': t['text'], 'start': t['start'], 'duration': t['duration']} for t in fetched], 'ko', 'subtitle'
            except:
                # í•œêµ­ì–´ ìë§‰ì´ ì—†ìœ¼ë©´ ì˜ì–´ ì‹œë„
                try:
                    transcript = transcript_list.find_transcript(['en'])
                    fetched = transcript.fetch()
                    time.sleep(0.5)  # ìš”ì²­ ì‚¬ì´ ë”œë ˆì´
                    return [{'text': t['text'], 'start': t['start'], 'duration': t['duration']} for t in fetched], 'en', 'subtitle'
                except:
                    # ìë™ ìƒì„± ìë§‰ ì‹œë„
                    transcript = transcript_list.find_generated_transcript(['ko'])
                    fetched = transcript.fetch()
                    time.sleep(0.5)  # ìš”ì²­ ì‚¬ì´ ë”œë ˆì´
                    return [{'text': t['text'], 'start': t['start'], 'duration': t['duration']} for t in fetched], 'ko', 'auto-generated'
                    
        except (TranscriptsDisabled, NoTranscriptFound):
            print(f"ì˜ìƒ {video_id}ì— ìë§‰ì´ ì—†ìŠµë‹ˆë‹¤. STTë¥¼ ì§„í–‰í•©ë‹ˆë‹¤...")
            return None, None, None
        except Exception as e:
            # IP ì°¨ë‹¨ ë“± ë‹¤ë¥¸ ì—ëŸ¬ ì²˜ë¦¬
            if 'blocking' in str(e).lower() or 'banned' in str(e).lower():
                print(f"âš ï¸ YouTube ìë§‰ API ì°¨ë‹¨ ê°ì§€: {e}")
                print(f"   ìë§‰ ì—†ì´ ì§„í–‰í•˜ê±°ë‚˜ STTë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤...")
                return None, None, None
            else:
                print(f"ìë§‰ ê°€ì ¸ì˜¤ê¸° ì—ëŸ¬: {e}")
                return None, None, None
    
    def download_audio(self, video_id, output_path='temp_audio'):
        """ì˜ìƒì˜ ì˜¤ë””ì˜¤ë§Œ ë‹¤ìš´ë¡œë“œ"""
        print(f"ì˜ìƒ {video_id}ì˜ ì˜¤ë””ì˜¤ë¥¼ ë‹¤ìš´ë¡œë“œí•˜ëŠ” ì¤‘...")
        
        os.makedirs(output_path, exist_ok=True)
        
        ydl_opts = {
            'format': 'bestaudio/best',
            'outtmpl': f'{output_path}/{video_id}.%(ext)s',
            'postprocessors': [{
                'key': 'FFmpegExtractAudio',
                'preferredcodec': 'mp3',
                'preferredquality': '192',
            }],
            'quiet': True,
            'no_warnings': True,
            # 403 ì—ëŸ¬ ë° IP ì°¨ë‹¨ ë°©ì§€ë¥¼ ìœ„í•œ ê°•í™” ì˜µì…˜
            'extractor_args': {
                'youtube': {
                    'player_client': ['ios', 'android', 'web'],
                    'skip': ['hls', 'dash']
                }
            },
            'http_headers': {
                'User-Agent': 'com.google.ios.youtube/19.09.3 (iPhone14,3; U; CPU iOS 15_6 like Mac OS X)',
                'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
                'Accept-Language': 'en-us,en;q=0.5',
                'Accept-Encoding': 'gzip, deflate',
                'Sec-Fetch-Mode': 'navigate',
            },
            'retries': 5,
            'fragment_retries': 5,
            'sleep_interval': 1,  # ìš”ì²­ ì‚¬ì´ ëŒ€ê¸° ì‹œê°„
            'max_sleep_interval': 3,
        }
        
        try:
            with yt_dlp.YoutubeDL(ydl_opts) as ydl:
                ydl.download([f'https://www.youtube.com/watch?v={video_id}'])
            return f'{output_path}/{video_id}.mp3'
        except Exception as e:
            print(f"ì˜¤ë””ì˜¤ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")
            return None
    
    def transcribe_audio(self, audio_path, model_size='base'):
        """Whisperë¥¼ ì‚¬ìš©í•˜ì—¬ ì˜¤ë””ì˜¤ë¥¼ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜"""
        print(f"ì˜¤ë””ì˜¤ë¥¼ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ëŠ” ì¤‘... (ëª¨ë¸: {model_size}, ë””ë°”ì´ìŠ¤: {self.device})")
        
        if self.whisper_model is None:
            print(f"Whisper ëª¨ë¸ ë¡œë”© ì¤‘... ({self.device})")
            self.whisper_model = whisper.load_model(model_size, device=self.device)
        
        try:
            result = self.whisper_model.transcribe(audio_path, language='ko', fp16=(self.device == "cuda"))
            
            # YouTube ìë§‰ í˜•ì‹ê³¼ ìœ ì‚¬í•˜ê²Œ ë³€í™˜
            segments = []
            for segment in result['segments']:
                segments.append({
                    'text': segment['text'],
                    'start': segment['start'],
                    'duration': segment['end'] - segment['start']
                })
            
            return segments, 'ko', 'whisper-stt'
        except Exception as e:
            print(f"STT ë³€í™˜ ì‹¤íŒ¨: {e}")
            return None, None, None
    
    def get_collected_video_ids(self, output_dir='youtube_data'):
        """ì´ë¯¸ ìˆ˜ì§‘ëœ ì˜ìƒ ID ëª©ë¡ ê°€ì ¸ì˜¤ê¸°"""
        channel_dir = os.path.join(output_dir, self.channel_id)
        if not os.path.exists(channel_dir):
            return set()
        
        collected_ids = set()
        # JSON íŒŒì¼ì—ì„œ video_id ì¶”ì¶œ
        json_files = glob.glob(f"{channel_dir}/*.json")
        for json_file in json_files:
            # channel_info.jsonì€ ì œì™¸
            if 'channel_info.json' in json_file:
                continue
            try:
                with open(json_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    if 'metadata' in data and 'video_id' in data['metadata']:
                        collected_ids.add(data['metadata']['video_id'])
            except:
                # íŒŒì¼ëª…ì—ì„œ video_id ì¶”ì¶œ (íŒŒì¼ëª… í˜•ì‹: video_id_timestamp.json)
                filename = os.path.basename(json_file)
                video_id = filename.split('_')[0]
                collected_ids.add(video_id)
        
        return collected_ids
    
    def save_data(self, video_data, output_dir='youtube_data'):
        """ë°ì´í„°ë¥¼ íŒŒì¼ë¡œ ì €ì¥"""
        # ì±„ë„ë³„ í´ë” ìƒì„± (ì±„ë„ IDë¡œ êµ¬ë¶„)
        channel_dir = os.path.join(output_dir, self.channel_id)
        os.makedirs(channel_dir, exist_ok=True)
        
        video_id = video_data['metadata']['video_id']
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        
        # ë©”íƒ€ë°ì´í„°ì™€ ì „ì‚¬ë³¸ì„ í•˜ë‚˜ì˜ JSON íŒŒì¼ë¡œ ì €ì¥
        output_file = f"{channel_dir}/{video_id}_{timestamp}.json"
        
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(video_data, f, ensure_ascii=False, indent=2)
        
        print(f"ë°ì´í„° ì €ì¥ ì™„ë£Œ: {output_file}")
        
        # ìë§‰/ì „ì‚¬ë³¸ì„ ë³„ë„ì˜ í…ìŠ¤íŠ¸ íŒŒì¼ë¡œë„ ì €ì¥
        if video_data.get('transcript'):
            txt_file = f"{channel_dir}/{video_id}_{timestamp}.txt"
            with open(txt_file, 'w', encoding='utf-8') as f:
                f.write(f"ì œëª©: {video_data['metadata']['title']}\n")
                f.write(f"URL: {video_data['metadata']['video_url']}\n")
                f.write(f"ì „ì‚¬ íƒ€ì…: {video_data['transcript_type']}\n\n")
                
                for segment in video_data['transcript']:
                    start_time = segment['start']
                    text = segment['text']
                    f.write(f"[{start_time:.2f}s] {text}\n")
            
            print(f"í…ìŠ¤íŠ¸ íŒŒì¼ ì €ì¥ ì™„ë£Œ: {txt_file}")
    
    def process_videos(self, max_videos=10, use_stt=True, whisper_model='base', skip_transcript_api=False):
        """ì „ì²´ í”„ë¡œì„¸ìŠ¤ ì‹¤í–‰
        
        Args:
            max_videos: ìˆ˜ì§‘í•  ìµœëŒ€ ì˜ìƒ ìˆ˜
            use_stt: ìë§‰ì´ ì—†ì„ ë•Œ STT ì‚¬ìš© ì—¬ë¶€
            whisper_model: Whisper ëª¨ë¸ í¬ê¸°
            skip_transcript_api: Trueë©´ ìë§‰ APIë¥¼ ê±´ë„ˆë›°ê³  ë°”ë¡œ STT ì‚¬ìš© (IP ì°¨ë‹¨ ì‹œ)
        """
        print(f"\n{'='*50}")
        print(f"YouTube ì±„ë„ ì˜ìƒ ìˆ˜ì§‘ ì‹œì‘")
        if skip_transcript_api:
            print(f"âš ï¸ ìë§‰ API ê±´ë„ˆë›°ê¸° ëª¨ë“œ (IP ì°¨ë‹¨ ìš°íšŒ)")
        print(f"{'='*50}\n")
        
        # ì´ë¯¸ ìˆ˜ì§‘ëœ ì˜ìƒ ID ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
        collected_ids = self.get_collected_video_ids()
        if collected_ids:
            print(f"ì´ë¯¸ ìˆ˜ì§‘ëœ ì˜ìƒ: {len(collected_ids)}ê°œ")
        
        # ìµœì‹  ì˜ìƒ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
        video_ids = self.get_latest_videos(max_videos)
        
        # ìƒˆë¡œìš´ ì˜ìƒë§Œ í•„í„°ë§
        new_video_ids = [vid for vid in video_ids if vid not in collected_ids]
        skipped_count = len(video_ids) - len(new_video_ids)
        
        if skipped_count > 0:
            print(f"ì¤‘ë³µ ê±´ë„ˆë›°ê¸°: {skipped_count}ê°œ")
        if new_video_ids:
            print(f"ìƒˆë¡œìš´ ì˜ìƒ: {len(new_video_ids)}ê°œ\n")
        else:
            print("ìˆ˜ì§‘í•  ìƒˆë¡œìš´ ì˜ìƒì´ ì—†ìŠµë‹ˆë‹¤.\n")
            return []
        
        # ì±„ë„ ì •ë³´ íŒŒì¼ ì €ì¥
        channel_info_dir = f"youtube_data/{self.channel_id}"
        os.makedirs(channel_info_dir, exist_ok=True)
        channel_info_file = f"{channel_info_dir}/channel_info.json"
        
        # ì²« ë²ˆì§¸ ì˜ìƒì˜ ë©”íƒ€ë°ì´í„°ì—ì„œ ì±„ë„ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
        first_metadata = self.get_video_metadata(new_video_ids[0])
        if first_metadata:
            # ê¸°ì¡´ channel_infoê°€ ìˆìœ¼ë©´ ì½ì–´ì˜¤ê¸°
            total_collected = len(collected_ids) + len(new_video_ids)
            channel_info = {
                'channel_id': self.channel_id,
                'channel_title': first_metadata['channel_title'],
                'last_updated': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                'total_videos_collected': total_collected
            }
            with open(channel_info_file, 'w', encoding='utf-8') as f:
                json.dump(channel_info, f, ensure_ascii=False, indent=2)
            print(f"ì±„ë„ ì •ë³´ ì—…ë°ì´íŠ¸: {channel_info_file}\n")
        
        results = []
        
        for idx, video_id in enumerate(new_video_ids, 1):
            print(f"\n[{idx}/{len(new_video_ids)}] ì²˜ë¦¬ ì¤‘: {video_id}")
            print("-" * 50)
            
            # ë©”íƒ€ë°ì´í„° ìˆ˜ì§‘
            metadata = self.get_video_metadata(video_id)
            if not metadata:
                print(f"ë©”íƒ€ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê±´ë„ˆëœë‹ˆë‹¤.")
                continue
            
            video_data = {
                'metadata': metadata,
                'transcript': None,
                'transcript_language': None,
                'transcript_type': None
            }
            
            # ìë§‰ ê°€ì ¸ì˜¤ê¸° ì‹œë„
            transcript = None
            lang = None
            trans_type = None
            
            if not skip_transcript_api:
                transcript, lang, trans_type = self.get_transcript(video_id)
            else:
                print(f"ìë§‰ API ê±´ë„ˆë›°ê¸° - STTë¡œ ì§ì ‘ ì§„í–‰")
            
            if transcript:
                video_data['transcript'] = transcript
                video_data['transcript_language'] = lang
                video_data['transcript_type'] = trans_type
                print(f"ìë§‰ ìˆ˜ì§‘ ì™„ë£Œ (ì–¸ì–´: {lang}, íƒ€ì…: {trans_type})")
            elif use_stt:
                # ìë§‰ì´ ì—†ìœ¼ë©´ STT ìˆ˜í–‰
                audio_path = self.download_audio(video_id)
                
                if audio_path and os.path.exists(audio_path):
                    transcript, lang, trans_type = self.transcribe_audio(audio_path, whisper_model)
                    
                    if transcript:
                        video_data['transcript'] = transcript
                        video_data['transcript_language'] = lang
                        video_data['transcript_type'] = trans_type
                        print(f"STT ë³€í™˜ ì™„ë£Œ (ì–¸ì–´: {lang})")
                    
                    # ì„ì‹œ ì˜¤ë””ì˜¤ íŒŒì¼ ì‚­ì œ
                    try:
                        os.remove(audio_path)
                    except:
                        pass
            
            # ë°ì´í„° ì €ì¥
            self.save_data(video_data)
            results.append(video_data)
            
            # ì˜ìƒ ì²˜ë¦¬ ì‚¬ì´ ë”œë ˆì´ (IP ì°¨ë‹¨ ë°©ì§€)
            time.sleep(1)
        
        print(f"\n{'='*50}")
        print(f"ì²˜ë¦¬ ì™„ë£Œ! ìƒˆë¡œ ìˆ˜ì§‘: {len(results)}ê°œ, ì „ì²´: {len(collected_ids) + len(results)}ê°œ")
        print(f"{'='*50}\n")
        
        return results


if __name__ == "__main__":
    # ======== ì„¤ì • ========
    
    # âš ï¸ IP ì°¨ë‹¨ ê²½ê³ ê°€ ë‚˜íƒ€ë‚˜ë©´ ì•„ë˜ ì˜µì…˜ë“¤ì„ ë³€ê²½í•˜ì„¸ìš”
    
    # ì˜µì…˜ 1: ìë§‰ API ê±´ë„ˆë›°ê¸° (ìë§‰ ì—†ì´ STTë§Œ ì‚¬ìš©)
    SKIP_TRANSCRIPT_API = True  # IP ì°¨ë‹¨ìœ¼ë¡œ ì¸í•´ Trueë¡œ ë³€ê²½
    
    # ì˜µì…˜ 2: STT ì‚¬ìš© (ì¤‘ìš”!)
    # Falseë©´ ë©”íƒ€ë°ì´í„°ë§Œ ìˆ˜ì§‘, Trueë©´ Whisperë¡œ ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
    USE_STT = True  # True: STT ì‚¬ìš© (ê¶Œì¥), False: ë©”íƒ€ë°ì´í„°ë§Œ ìˆ˜ì§‘
    
    # ì—¬ëŸ¬ API í‚¤ë¥¼ ìˆœí™˜ ì‚¬ìš©í•˜ì—¬ ì¿¼í„° ì œí•œ ìš°íšŒ
    # í™˜ê²½ ë³€ìˆ˜ì—ì„œ YouTube API í‚¤ë¥¼ ì½¤ë§ˆë¡œ êµ¬ë¶„í•´ ì—¬ëŸ¬ ê°œ ì„¤ì • ê°€ëŠ¥
    # ì˜ˆ: YOUTUBE_API_KEYS=key1,key2,key3
    import os
    _keys_str = os.getenv("YOUTUBE_API_KEYS", os.getenv("YOUTUBE_API_KEY", ""))
    API_KEYS = [k.strip() for k in _keys_str.split(",") if k.strip()]
    
    # ìˆ˜ì§‘í•  ì±„ë„ ID ë¦¬ìŠ¤íŠ¸ (ì±„ë„ URLì—ì„œ í™•ì¸)
    CHANNEL_IDS = [
       # "UCJvR4zNAPRJoMDF3A912dBA", 
       #  
       # top30 popular genz influencers
        #'UCWkYXtnAuu7VTLPwUcRSB6A', 'UCi3OE-aN09WOcN9d2stCvPg', 'UCAgIfWgzZ6QtvB_Oj1SBNnA', 'UC86suRFnqiw8zN6LIYxddYQ', 'UC78cxCAcp7JfQPgKxYdyGrg', 'UCJ48BrODPTg4RJBLNIj9J1Q', 'UCTn6eUt2dRO_iaH_q49yHzg', 'UCIfeSCjbA3koG9u7RHrrrOg', 'UC3EFKdXAU99j3ppGgvTz7XQ', 'UC-F3kTU4V680v550AavEOsQ', 'UC6QWhGQqf0YDYdRb0n6ojWw', 'UCucot-Zp428OwkyRm2I7v2Q', 'UCy96nw0qjQYc6WJZ8odwioQ', 'UCvTX9IDOCS_Ax2v0zN8PuwA', 'UC_CICrZWlIAyraLU7T1NBGw', 'UCf5Z8I0Yy0_-a-xAu2_0Yiw', 'UCiGWpX9oCmMu3hRUV_ZBvpg'# Emma Chamberlain
        # iphone vlogger list
        'UCaUgbmxXHCTXXkaJdmbuyIA', 'UCdc8lZHOvCQC89AUvN5nYdg', 
        'UC_0RAMKsGbvNujWt6RZZHIw', 'UCA6fMo3G4PNCuw6Ndzdo_Xg', 
        'UCb4aFIfcJZY8y2T2MkKD2eg', 'UCIPigoUn9DZl6XSuBxoydQg', 
        'UCvs8YG-yhlHx9qiq8Akrgrw', 'UC6go9qixF_GnKTbn2AGiYKQ', 
        'UCvAHILjsHJF9r2qSS-BAmYA', 'UCCeXwLzVKZU7VW8qXis_UOQ', 
        'UCW-ORpg24g63xBDew6xEyTA', 'UCmWRQG-1pbzNyjl6FQ6oNtQ', 
        'UCvrgf-Y45oJBw1AQYTDNDmA', 'UCB90rkvVhNL-pFqG0xGJtmA', 
        'UCKbeOEcrZb48MKR50EPgKHg', 'UCnz2_V9spAVIQXlTBFsWq1Q', 
        'UC5-E_dowa1WfHYz6eSTGTHQ', 'UCe1rRMQKy5JK7jFRZ_6pBtA', 
        'UCdUs3rJr3d1s-3Txm020-4A', 'UClaYO_c9NCWYWiontYW9i-Q', 
        'UCcD-DpQztF3fymfagC73fYg', 'UCLW0s6QUE-k87R9XQ7G3hTQ', 
        'UCDOJLR72Jj-lEviJdwU4G6g', 'UCg9BcSjR7l30TfgOvichwxw', 
        'UCfldmO5aM5zFpoA7pnPWB8A', 'UCbgqlUD84KKSujlUkmJNeDg', 
        'UCaW4E4J01Q5dmAAj8gezC_w', 'UCcyoi1KF9tpmlNWTFuBVk6A', 
        'UCxwZdNG1O66quSv9YK6CHmw', 'UCsJmcwKLnwPkwCCD8nXB5LQ', 
        'UCxNhswggApcm_ZpfWM-ihsg', 'UCxw_JBZaRWtL6JKvyxdUx5g', 
        'UCJXwJLW_RY-5zgOiyar3hYQ', 'UCoZ1s8gr_CycBLdWND-1HPA', 
        'UCqFilu6VGpDx-4B_g2jX0Xg', 'UCXwpFRuIEVQ6aSxN_uM1ldA', 
        'UCjFFNcfgIpKFuoqrBc7-iXQ', 'UC2cFvIqq9J10Vwx6kw3Mfvg', 
        'UC5W81PwG9xqUReQH2TW404Q', 'UC6BBzTpa1YF96JuPUMT9mWQ', 
        'UCvXd-ZMUYbQrj5EZCbkL7Mw', 'UC5uKMjPmITdRSA0405FFjug', 
        'UClf7V2Uqsp8bPrlXry0iTTA', 'UCP2uTYjohuUQklN1f9MFwrg', 
        'UCvd9M7scKQHzerck6tcYL-g', 'UC9GrfBvC7EDV9NsUDByDq3w', 
        'UCDMiCblpBbr6WqvodoV85xQ', 'UCSAazAJIiHDXYX7f4PRhjcg', 
        'UCaUpqLv4erEjme4YNquy2Qg', 'UC9PfekKMDzLt_tkragAeACw', 
        'UCRKAb1fHSOtLWDBi35ZDUvw', 'UCzrzxvTa2dHeNav7zl9L4Ug', 
        'UCfQx-K9zBExhMLfKQmXBxJg', 'UC5_cjRMuwhmEjj1Mh39JruQ', 
        
        'UCdrH8TMXN5dkomY0TKe7RIA', 'UC1J7puPhNHMONfKfCsNdTjQ', 
        'UCRtRPH0dz7THZLO9-NHFQbg', 'UCSucMa4aaOYOXe3y7IhelmA', 
        'UCP0R1BiTra_nLQXXyn4PzVQ', 'UCm0cV6cEa6iAgWSqBCyEndg', 
        'UCFM3hijh6mzg9buViYfbemQ', 'UCTt4TrACVRizUg73yO8fvdw', 
        'UCFmwE7aP8T_8FbuJS8lbdUQ', 'UCa3ylSmA2dg2tDmAeDsfaSg', 
        'UCff8p7TZgXxq3A6byvMH2CA', 'UCqRjPZ0vCzlAXCanFI3Fxrg', 
        'UCvxd9_WzHuPQcXPz8ODyfWA', 'UCyIRhcmxbD0nnAXX6Z8gvag', 'UCh7sFvTDwhy0ysjEqbVdABQ', 
        'UCyiyMB7zw_uIpID2rXC-0wA', 'UCiZoaJo2nM2D-gEUHpkJfhw', 'UCKYmTpdCkWK-gIdkxGK9S_A', 
        'UCA0oZ63wytik-f8HCz_umEQ', 'UCyAriCU7bpinmBzH_u5w4kw', 'UCjpU9XkqxBFvASqLTGrG8BA', 
        'UCWlNWKU7cn3fTxWJt1bw3mg', 'UCVKOBq9zfHIT9j7ZqPASKBQ', 'UCDUyDv6rywPxhdeRyA_KY4A', 
        'UCKWDKVjk2qcvRUShkUofkiw', 'UCKaCalz5N5ienIbfPzEbYuA', 'UCrs_Di9lLls_nvWnPNvk6OQ', 
        'UCqJ0QnHfvPMTSzxoWa-X9FQ', 'UCGbdpXT0waDfg330LsyzDEg', 'UCUfYnCDgbm6fKoJ9Gf7THfA', 'UCZI1v9kPAcr2rjp51SkDWhg',
         'UC3SafDS4jxWKROqzPaON0lA', 'UCrJv75V4Mh3tBmFwS_6b3mw', 'UCvPfa7yll5K_7VG5hA9lZVQ', 'UC8jtW4wcC226-zwBsLYUcDQ',
          'UCd0iAIdZxOGEgBBco9jaP4A', 'UC7xMBGa8dy0xVbhjNIY-nPg', 'UC7U_OqXVkRdGHxiUo4t9LgQ', 
          'UCuGHfFf4exFrBRAqy9cJAdg', 'UCq2GutDFXrztWzwiYmNv2HA', 'UCFW-K3Oor0MgElsg-6SfieA', 
          'UCeJICuSKNGMVQbAAzH6DcAw', 'UCzVfNcVh8Oj1rJgq1tjgF_w', 'UC46jnLaai5IRmHmuuHzx8sg', 
          'UCXm30w3cPvoZT3wZNRj9Jng', 'UCzbEcp0Lg1RiNJcnobwm5Sw'
    ]
    
    # ì „ì²´ ê²°ê³¼ ì €ì¥
    all_results = {}
    api_key_usage = {i: 0 for i in range(len(API_KEYS))}  # API í‚¤ë³„ ì‚¬ìš© íšŸìˆ˜ ì¶”ì 
    
    # ì´ˆê¸° API í‚¤ ì„¤ì •
    print(f"\n{'='*70}")
    print(f"ğŸ”‘ ì‚¬ìš© ê°€ëŠ¥í•œ API í‚¤: {len(API_KEYS)}ê°œ")
    print(f"   ê° ì±„ë„ë§ˆë‹¤ ìë™ìœ¼ë¡œ ìˆœí™˜ ì‚¬ìš©í•˜ì—¬ ì¿¼í„° ë¶„ì‚°!")
    print(f"{'='*70}\n")
    
    # ê° ì±„ë„ë³„ë¡œ ìŠ¤í¬ë˜í¼ ì‹¤í–‰
    for idx, channel_id in enumerate(CHANNEL_IDS, 1):
        print(f"\n{'='*70}")
        print(f"ì±„ë„ [{idx}/{len(CHANNEL_IDS)}] ì²˜ë¦¬ ì¤‘: {channel_id}")
        print(f"{'='*70}")
        
        # API í‚¤ ìˆœí™˜ ì‚¬ìš©
        api_key_tried = 0
        success = False
        
        while api_key_tried < len(API_KEYS) and not success:
            # í˜„ì¬ API í‚¤ ì„ íƒ
            current_key_idx = (idx - 1 + api_key_tried) % len(API_KEYS)
            current_api_key = API_KEYS[current_key_idx]
            
            print(f"ğŸ”‘ API í‚¤ [{current_key_idx + 1}/{len(API_KEYS)}] ì‚¬ìš© ì¤‘...")
            
            try:
                # ìŠ¤í¬ë˜í¼ ì´ˆê¸°í™”
                scraper = YouTubeChannelScraper(current_api_key, channel_id)
            
                # ìµœì‹  100ê°œ ì˜ìƒ ì²˜ë¦¬
                # use_stt=True: ìë§‰ì´ ì—†ìœ¼ë©´ STT ìˆ˜í–‰
                # whisper_model: 'tiny', 'base', 'small', 'medium', 'large' ì¤‘ ì„ íƒ
                #                (í¬ê¸°ê°€ í´ìˆ˜ë¡ ì •í™•ë„ ë†’ì§€ë§Œ ì†ë„ ëŠë¦¼)
                # skip_transcript_api=True: IP ì°¨ë‹¨ ì‹œ ìë§‰ APIë¥¼ ê±´ë„ˆë›°ê³  STTë§Œ ì‚¬ìš©
                results = scraper.process_videos(
                    max_videos=100,
                    use_stt=USE_STT,
                    whisper_model='base',
                    skip_transcript_api=SKIP_TRANSCRIPT_API
                )
                
                all_results[channel_id] = results
                success = True
                api_key_usage[current_key_idx] += 1  # API í‚¤ ì‚¬ìš© íšŸìˆ˜ ì¦ê°€
                
                print(f"\nâœ“ ì±„ë„ {channel_id}: {len(results)}ê°œ ì˜ìƒ ìˆ˜ì§‘ ì™„ë£Œ (API í‚¤ #{current_key_idx + 1})")
                
            except Exception as e:
                error_msg = str(e)
                
                # API ì¿¼í„° ì—ëŸ¬ ì²´í¬
                if 'quota' in error_msg.lower() or 'limit' in error_msg.lower() or '403' in error_msg:
                    print(f"\nâš ï¸ API ì¿¼í„° ì œí•œ! ë‹¤ìŒ API í‚¤ë¡œ ì „í™˜í•©ë‹ˆë‹¤...")
                    api_key_tried += 1
                    
                    if api_key_tried >= len(API_KEYS):
                        print(f"\nâŒ ëª¨ë“  API í‚¤ì˜ ì¿¼í„°ê°€ ì†Œì§„ë˜ì—ˆìŠµë‹ˆë‹¤!")
                        print(f"   ë‚´ì¼ ë‹¤ì‹œ ì‹œë„í•˜ê±°ë‚˜ ìƒˆë¡œìš´ API í‚¤ë¥¼ ì¶”ê°€í•˜ì„¸ìš”.")
                        break
                else:
                    # ë‹¤ë¥¸ ì—ëŸ¬ëŠ” ë°”ë¡œ ì¢…ë£Œ
                    print(f"\nâœ— ì±„ë„ {channel_id} ì²˜ë¦¬ ì¤‘ ì—ëŸ¬ ë°œìƒ: {e}")
                    import traceback
                    traceback.print_exc()
                    break
        
        if not success:
            print(f"\nâš ï¸ ì±„ë„ {channel_id} ìˆ˜ì§‘ ì‹¤íŒ¨ - ë‹¤ìŒ ì±„ë„ë¡œ ì´ë™...")
            continue
    
    # ì „ì²´ ìˆ˜ì§‘ ê²°ê³¼ ìš”ì•½
    print(f"\n{'='*70}")
    print(f"ì „ì²´ ìˆ˜ì§‘ ì™„ë£Œ!")
    print(f"{'='*70}")
    print(f"ì´ {len(CHANNEL_IDS)}ê°œ ì±„ë„, {sum(len(v) for v in all_results.values())}ê°œ ì˜ìƒ ìˆ˜ì§‘\n")
    
    # API í‚¤ ì‚¬ìš© í†µê³„
    print(f"{'â”€'*70}")
    print(f"ğŸ”‘ API í‚¤ ì‚¬ìš© í†µê³„:")
    print(f"{'â”€'*70}")
    for key_idx, usage_count in api_key_usage.items():
        if usage_count > 0:
            print(f"   API í‚¤ #{key_idx + 1}: {usage_count}ê°œ ì±„ë„ ì²˜ë¦¬")
    print()
    
    for channel_id, results in all_results.items():
        if results:
            print(f"\nì±„ë„: {channel_id} ({results[0]['metadata']['channel_title']})")
            print(f"ìˆ˜ì§‘ëœ ì˜ìƒ: {len(results)}ê°œ")
            for video in results:
                print(f"  - {video['metadata']['title']}")
                print(f"    ì¡°íšŒìˆ˜: {video['metadata']['view_count']}, ì¢‹ì•„ìš”: {video['metadata']['like_count']}")
                print(f"    ìë§‰/STT: {video['transcript_type']}")
            print()
