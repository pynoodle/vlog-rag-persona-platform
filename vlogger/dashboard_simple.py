# -*- coding: utf-8 -*-
import streamlit as st
import pandas as pd
import plotly.express as px
import json
import os
import glob
from collections import Counter

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="YouTube ì˜ìƒ ë°ì´í„° ë¶„ì„",
    page_icon="ğŸ“±",
    layout="wide"
)

@st.cache_data
def load_data():
    """ë°ì´í„° ë¡œë“œ"""
    videos = []
    data_dir = 'youtube_data'
    
    if not os.path.exists(data_dir):
        return videos
    
    for channel_dir in os.listdir(data_dir):
        channel_path = os.path.join(data_dir, channel_dir)
        if not os.path.isdir(channel_path):
            continue
        
        # ì±„ë„ ì •ë³´
        channel_info = os.path.join(channel_path, 'channel_info.json')
        channel_name = channel_dir
        
        if os.path.exists(channel_info):
            try:
                with open(channel_info, 'r', encoding='utf-8') as f:
                    info = json.load(f)
                    channel_name = info.get('channel_title', channel_dir)
            except:
                pass
        
        # ì˜ìƒ ë°ì´í„°
        for json_file in glob.glob(os.path.join(channel_path, '*.json')):
            if 'channel_info' in json_file:
                continue
            
            try:
                with open(json_file, 'r', encoding='utf-8') as f:
                    video = json.load(f)
                
                video['channel_name'] = channel_name
                
                # ì „ì²´ í…ìŠ¤íŠ¸ ìƒì„±
                full_text = ""
                if video.get('transcript'):
                    full_text = " ".join([s.get('text', '') for s in video['transcript']])
                
                video['full_text'] = full_text
                videos.append(video)
            except:
                continue
    
    return videos

# ë©”ì¸
st.title("ğŸ“± YouTube ì˜ìƒ ë°ì´í„° ë¶„ì„ ëŒ€ì‹œë³´ë“œ")

# ë°ì´í„° ë¡œë“œ
videos = load_data()

if not videos:
    st.error("ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    st.stop()

videos_with_text = [v for v in videos if v.get('full_text')]

# íƒ­
tab1, tab2, tab3, tab4 = st.tabs(["ğŸ“Š í†µê³„", "ğŸ” ê²€ìƒ‰", "ğŸ“º ì±„ë„", "ğŸ”¥ ì¸ê¸°"])

# íƒ­ 1: í†µê³„
with tab1:
    st.header("ğŸ“Š ì „ì²´ í†µê³„")
    
    col1, col2, col3, col4 = st.columns(4)
    col1.metric("ì´ ì˜ìƒ", f"{len(videos):,}")
    col2.metric("ì±„ë„ ìˆ˜", f"{len(set(v['channel_name'] for v in videos))}")
    col3.metric("ìë§‰/STT", f"{len(videos_with_text):,}")
    
    rate = len(videos_with_text) / len(videos) * 100 if videos else 0
    col4.metric("ìˆ˜ì§‘ë¥ ", f"{rate:.1f}%")
    
    st.markdown("---")
    
    # ì±„ë„ë³„ ì˜ìƒ ìˆ˜
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("ì±„ë„ë³„ ì˜ìƒ ìˆ˜ (Top 15)")
        channel_counts = Counter(v['channel_name'] for v in videos)
        df = pd.DataFrame(channel_counts.most_common(15), columns=['ì±„ë„', 'ì˜ìƒìˆ˜'])
        
        fig = px.bar(df, x='ì˜ìƒìˆ˜', y='ì±„ë„', orientation='h')
        fig.update_layout(height=500)
        st.plotly_chart(fig, use_container_width=True)
    
    with col2:
        st.subheader("ìë§‰ íƒ€ì… ë¶„í¬")
        types = Counter(v.get('transcript_type', 'none') for v in videos)
        df_types = pd.DataFrame(types.items(), columns=['íƒ€ì…', 'ê°œìˆ˜'])
        
        type_map = {
            'subtitle': 'ğŸ“„ ìˆ˜ë™ìë§‰',
            'auto-generated': 'ğŸ¤– ìë™ìƒì„±',
            'whisper-stt': 'ğŸ™ï¸ Whisper',
            'none': 'âŒ ì—†ìŒ',
            None: 'âŒ ì—†ìŒ'
        }
        df_types['íƒ€ì…'] = df_types['íƒ€ì…'].map(lambda x: type_map.get(x, x))
        
        fig = px.pie(df_types, values='ê°œìˆ˜', names='íƒ€ì…')
        fig.update_layout(height=500)
        st.plotly_chart(fig, use_container_width=True)

# íƒ­ 2: ê²€ìƒ‰
with tab2:
    st.header("ğŸ” í‚¤ì›Œë“œ ê²€ìƒ‰")
    
    keyword = st.text_input("ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•˜ì„¸ìš”", placeholder="ì˜ˆ: ì•„ì´í°, battery, ì¼€ì´ìŠ¤")
    
    if keyword:
        st.info(f"ğŸ” '{keyword}' ê²€ìƒ‰ ì¤‘...")
        
        results = []
        for video in videos_with_text:
            if keyword.lower() in video['full_text'].lower():
                count = video['full_text'].lower().count(keyword.lower())
                results.append({
                    'channel': video['channel_name'],
                    'title': video['metadata']['title'],
                    'url': video['metadata']['video_url'],
                    'views': int(video['metadata'].get('view_count', 0)),
                    'count': count,
                    'video': video
                })
        
        results.sort(key=lambda x: x['count'], reverse=True)
        
        if results:
            st.success(f"âœ… {len(results)}ê°œ ì˜ìƒì—ì„œ ì´ {sum(r['count'] for r in results)}íšŒ ë°œê²¬!")
            
            for idx, r in enumerate(results[:15], 1):
                st.markdown(f"### {idx}. {r['title']}")
                st.write(f"**ì±„ë„:** {r['channel']} | **ì–¸ê¸‰:** {r['count']}íšŒ | **ì¡°íšŒìˆ˜:** {r['views']:,}")
                st.write(f"**URL:** {r['url']}")
                
                # ì˜ˆì‹œ ì„¸ê·¸ë¨¼íŠ¸
                for seg in r['video']['transcript']:
                    if keyword.lower() in seg.get('text', '').lower():
                        ts = seg.get('start', 0)
                        m, s = int(ts // 60), int(ts % 60)
                        st.caption(f"[{m:02d}:{s:02d}] {seg.get('text', '')[:150]}")
                        break
                
                st.markdown("---")
        else:
            st.warning(f"'{keyword}'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

# íƒ­ 3: ì±„ë„
with tab3:
    st.header("ğŸ“º ì±„ë„ë³„ ë¶„ì„")
    
    channels = sorted(list(set(v['channel_name'] for v in videos)))
    selected = st.selectbox("ì±„ë„ ì„ íƒ", channels)
    
    if selected:
        ch_videos = [v for v in videos if v['channel_name'] == selected]
        ch_with_text = [v for v in ch_videos if v.get('full_text')]
        
        col1, col2, col3 = st.columns(3)
        col1.metric("ì´ ì˜ìƒ", f"{len(ch_videos)}")
        col2.metric("ìë§‰/STT", f"{len(ch_with_text)}")
        
        total_views = sum(int(v['metadata'].get('view_count', 0)) for v in ch_videos)
        col3.metric("ì´ ì¡°íšŒìˆ˜", f"{total_views:,}")
        
        st.markdown("---")
        st.subheader("ì˜ìƒ ëª©ë¡")
        
        for idx, v in enumerate(sorted(ch_videos, 
                                       key=lambda x: int(x['metadata'].get('view_count', 0)),
                                       reverse=True)[:20], 1):
            meta = v['metadata']
            st.write(f"**{idx}. {meta['title']}**")
            st.write(f"ì¡°íšŒìˆ˜: {int(meta.get('view_count', 0)):,} | ìë§‰: {'âœ…' if v.get('full_text') else 'âŒ'}")
            st.caption(meta['video_url'])
            st.markdown("---")

# íƒ­ 4: ì¸ê¸° ì˜ìƒ
with tab4:
    st.header("ğŸ”¥ ì¸ê¸° ì˜ìƒ Top 20")
    
    filter_opt = st.radio("í•„í„°", ["ì „ì²´", "ìŠ¤ë§ˆíŠ¸í° ê´€ë ¨"], horizontal=True)
    
    to_rank = videos.copy()
    
    if filter_opt == "ìŠ¤ë§ˆíŠ¸í° ê´€ë ¨":
        keywords = ['iphone', 'phone', 'smartphone', 'galaxy', 'android',
                   'ì•„ì´í°', 'í°', 'ìŠ¤ë§ˆíŠ¸í°', 'ê°¤ëŸ­ì‹œ']
        to_rank = [v for v in videos_with_text 
                   if any(k.lower() in v['full_text'].lower() for k in keywords)]
    
    to_rank.sort(key=lambda x: int(x['metadata'].get('view_count', 0)), reverse=True)
    
    for idx, v in enumerate(to_rank[:20], 1):
        meta = v['metadata']
        
        col1, col2 = st.columns([4, 1])
        
        with col1:
            st.markdown(f"### {idx}. {meta['title']}")
            st.write(f"**ì±„ë„:** {v['channel_name']}")
            st.caption(meta['video_url'])
        
        with col2:
            views = int(meta.get('view_count', 0))
            st.metric("ì¡°íšŒìˆ˜", f"{views:,}")
        
        st.markdown("---")

# ì‚¬ì´ë“œë°”
st.sidebar.header("ğŸ“Š í˜„ì¬ ìƒíƒœ")
st.sidebar.metric("ì˜ìƒ", f"{len(videos)}")
st.sidebar.metric("ìë§‰/STT", f"{len(videos_with_text)}")
st.sidebar.metric("ì±„ë„", f"{len(set(v['channel_name'] for v in videos))}")

